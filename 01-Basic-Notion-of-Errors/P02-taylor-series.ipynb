{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Taylor Series and Numerical Stability\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Many functions in mathematics, such as $e^x$, $\\sin(x)$, or $\\ln(x)$, cannot be computed directly using simple arithmetic operations. Instead, we can approximate them using **Taylor series**, which represent a function as an infinite sum of its derivatives at a single point.\n",
    "\n",
    "The Taylor series expansion of a function $f(x)$ around a point $a$ is given by:\n",
    "$$ f(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(a)}{k!} (x-a)^k = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2!}(x-a)^2 + \\cdots $$\n",
    "\n",
    "A special case of this series, when centered around $a=0$, is called the **Maclaurin series**. In this notebook, we will explore the Maclaurin series for $f(x) = e^x$ and uncover critical challenges related to its practical implementation, including numerical stability and computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Maclaurin Series for $e^x$\n",
    "\n",
    "The function $f(x) = e^x$ is unique because all of its derivatives are also $e^x$. When we evaluate these derivatives at $a=0$, we find that $f^{(k)}(0) = e^0 = 1$ for all $k$.\n",
    "\n",
    "Plugging this into the Maclaurin series formula gives us the elegant expansion for $e^x$:\n",
    "$$ e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} = 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\cdots $$\n",
    "\n",
    "This series allows us to approximate $e^x$ using only basic arithmetic. The more terms we include in our sum, the closer our approximation gets to the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def taylor_exp_naive(x, n_terms):\n",
    "    \"\"\"A naive computation of e^x using its Taylor series up to n_terms.\"\"\"\n",
    "    # Start with the first term (k=0), which is 1\n",
    "    approximation = 1.0\n",
    "    \n",
    "    # Add terms from k=1 up to n_terms-1\n",
    "    for k in range(1, n_terms):\n",
    "        approximation += (x**k) / math.factorial(k)\n",
    "        \n",
    "    return approximation\n",
    "\n",
    "# --- Visualization ---\n",
    "x_vals = np.linspace(-3, 3, 400)\n",
    "true_vals = np.exp(x_vals)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_vals, true_vals, label='True $e^x$', color='black', linewidth=2)\n",
    "\n",
    "# Plot approximations with different numbers of terms\n",
    "for n in [2, 3, 5, 8]:\n",
    "    approx_vals = [taylor_exp_naive(x, n) for x in x_vals]\n",
    "    plt.plot(x_vals, approx_vals, label=f'{n} terms', linestyle='--')\n",
    "\n",
    "plt.title('Approximating $e^x$ with its Maclaurin Series')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.ylim(-1, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that as we add more terms, the approximation hugs the true function curve more closely, especially for `x` values near the center (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Problem with Negative Inputs: Catastrophic Cancellation\n",
    "\n",
    "While the series formula works for all $x$, it becomes numerically unstable when $x$ is a large negative number. Let's examine the series for $e^{-20}$:\n",
    "$$ e^{-20} = 1 - \\frac{20}{1!} + \\frac{20^2}{2!} - \\frac{20^3}{3!} + \\cdots = 1 - 20 + 200 - 1333.33 + \\cdots $$\n",
    "\n",
    "The true value of $e^{-20}$ is a very small positive number (approx. $2.06 \\times 10^{-9}$). However, to calculate it, the series forces us to sum very large positive and negative numbers. This is a classic recipe for **catastrophic cancellation**.\n",
    "\n",
    "When we subtract two nearly equal numbers, most of the leading, significant digits cancel out, leaving a result dominated by the less-significant digits, which are contaminated by rounding errors. This leads to a massive loss of precision.\n",
    "\n",
    "### A Numerically Stable Alternative\n",
    "\n",
    "A much better way to compute $e^x$ for a negative $x$ is to use the identity:\n",
    "$$ e^x = \\frac{1}{e^{-x}} $$\n",
    "\n",
    "If $x$ is negative, then $y = -x$ is positive. We can compute the Taylor series for $e^y$ (which is stable as it only involves adding positive terms) and then take its reciprocal.\n",
    "\n",
    "Let's compare these two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_negative_x_methods(x, n_terms_max):\n",
    "    \"\"\"Compares the direct (unstable) vs. reciprocal (stable) methods for e^x where x < 0.\"\"\"\n",
    "    if x >= 0:\n",
    "        print(\"This function is for demonstrating issues with negative x.\")\n",
    "        return\n",
    "\n",
    "    true_value = np.exp(x)\n",
    "    y = -x\n",
    "    \n",
    "    n_values = range(1, n_terms_max + 1)\n",
    "    direct_errors = []\n",
    "    reciprocal_errors = []\n",
    "\n",
    "    for n in n_values:\n",
    "        # Method 1: Direct, unstable calculation\n",
    "        direct_approx = taylor_exp_naive(x, n)\n",
    "        direct_errors.append(abs(direct_approx - true_value))\n",
    "        \n",
    "        # Method 2: Stable, reciprocal calculation\n",
    "        reciprocal_approx = 1 / taylor_exp_naive(y, n)\n",
    "        reciprocal_errors.append(abs(reciprocal_approx - true_value))\n",
    "        \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogy(n_values, direct_errors, 'r-o', label='Direct Method (Unstable)')\n",
    "    plt.semilogy(n_values, reciprocal_errors, 'g-o', label='Reciprocal Method (Stable)')\n",
    "    \n",
    "    plt.title(f'Absolute Error in Calculating $e^{{{x}}}$ vs. Number of Terms')\n",
    "    plt.xlabel('Number of Terms (n)')\n",
    "    plt.ylabel('Absolute Error (log scale)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.show()\n",
    "\n",
    "# Test with a large negative number\n",
    "compare_negative_x_methods(x=-20, n_terms_max=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of the Plot:**\n",
    "\n",
    "- The **stable (reciprocal) method** converges beautifully. As we add more terms, the error consistently decreases, approaching the limits of machine precision.\n",
    "- The **unstable (direct) method** is a complete disaster. The error initially decreases, but as the terms in the series grow larger, catastrophic cancellation kicks in, and the error explodes. The final result is meaningless.\n",
    "\n",
    "This powerfully illustrates why the choice of algorithm is just as important as the mathematical formula itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improving Efficiency and Avoiding Overflow\n",
    "\n",
    "Our `taylor_exp_naive` function is clear, but it's very inefficient for two reasons:\n",
    "1.  **Repeated Calculations**: In each loop, we compute `x**k` and `math.factorial(k)` from scratch. This is wasteful.\n",
    "2.  **Overflow Risk**: The factorial function `k!` grows incredibly fast. For even moderately large `k` (e.g., `k > 170`), `math.factorial(k)` will cause an overflow error, crashing the program.\n",
    "\n",
    "We can solve both problems by calculating each term **iteratively** based on the previous one. Notice the relationship between consecutive terms:\n",
    "$$ \\text{Term}_k = \\frac{x^k}{k!} = \\frac{x^{k-1}}{(k-1)!} \\cdot \\frac{x}{k} = \\text{Term}_{k-1} \\cdot \\frac{x}{k} $$\n",
    "\n",
    "This allows us to compute each new term with just one multiplication and one division, completely avoiding large intermediate numbers from factorials and powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor_exp_efficient(x, n_terms):\n",
    "    \"\"\"An efficient and stable computation of e^x using its Taylor series.\"\"\"\n",
    "    current_term = 1.0\n",
    "    approximation = 1.0\n",
    "    \n",
    "    for k in range(1, n_terms):\n",
    "        # Calculate the next term from the previous one\n",
    "        current_term *= x / k\n",
    "        approximation += current_term\n",
    "        \n",
    "    return approximation\n",
    "\n",
    "# Let's quickly verify it gives the same results as the naive version\n",
    "x_val = 5\n",
    "n_val = 15\n",
    "print(f\"Naive method result:    {taylor_exp_naive(x_val, n_val)}\")\n",
    "print(f\"Efficient method result:  {taylor_exp_efficient(x_val, n_val)}\")\n",
    "print(f\"np.exp result:          {np.exp(x_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Implementation: Using a Stopping Criterion\n",
    "\n",
    "In a real application, we don't want to specify the number of terms `n` manually. A better approach is to continue adding terms until they become so small that they no longer contribute meaningfully to the sum. This is known as a **stopping criterion**.\n",
    "\n",
    "We can stop the loop when the absolute value of the `current_term` falls below a certain tolerance (e.g., `1e-9`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_exp_taylor(x, tolerance=1e-9):\n",
    "    \"\"\"\n",
    "    A robust function to calculate e^x using the most stable and efficient methods.\n",
    "    - Handles negative x using the reciprocal method.\n",
    "    - Uses an efficient iterative term calculation.\n",
    "    - Stops when the terms become smaller than a specified tolerance.\n",
    "    \"\"\"\n",
    "    # Use the stable reciprocal method for negative x\n",
    "    if x < 0:\n",
    "        return 1 / robust_exp_taylor(-x, tolerance)\n",
    "    \n",
    "    current_term = 1.0\n",
    "    approximation = 1.0\n",
    "    k = 1\n",
    "    \n",
    "    while abs(current_term) > tolerance:\n",
    "        current_term *= x / k\n",
    "        approximation += current_term\n",
    "        k += 1\n",
    "        # Safety break to prevent infinite loops, though unlikely here\n",
    "        if k > 1000: \n",
    "            break\n",
    "            \n",
    "    return approximation, k\n",
    "\n",
    "# --- Testing the final function ---\n",
    "test_values = [1, 5, 20, -1, -5, -20]\n",
    "\n",
    "print(f\"{'x':>5} | {'Taylor Approx':>20} | {'True Value':>20} | {'Terms Used':>12}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for val in test_values:\n",
    "    approx, terms = robust_exp_taylor(val)\n",
    "    true_val = np.exp(val)\n",
    "    print(f\"{val:>5} | {approx:>20.15f} | {true_val:>20.15f} | {terms:>12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This exploration of the Taylor series for $e^x$ has provided several crucial insights into numerical methods:\n",
    "\n",
    "1.  **Numerical Stability is Paramount**: A mathematically correct formula can produce completely wrong results if it is not implemented in a stable way. Rearranging the problem (like using $1/e^{-x}$) is a common and powerful technique.\n",
    "2.  **Computational Efficiency Matters**: Re-calculating values like factorials is slow and risky. Iterative methods that build upon previous results are often far superior.\n",
    "3.  **Stopping Criteria are Practical**: In practice, iterative algorithms are terminated based on a tolerance, not a fixed number of steps, ensuring that just enough work is done to achieve the desired accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}