{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - LU Decomposition\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "**LU Decomposition** is a method of factoring a square matrix $A$ into the product of two other matrices: a **lower triangular matrix ($L$)** and an **upper triangular matrix ($U$)**.\n",
    "\n",
    "$$ A = L \\cdot U $$\n",
    "\n",
    "The structure of these matrices is typically:\n",
    "- **$L$ (Lower Triangular)**: Has ones on its main diagonal and zeros above it.\n",
    "- **$U$ (Upper Triangular)**: Has the pivots from the elimination process on its main diagonal and zeros below it.\n",
    "\n",
    "For example:\n",
    "$$ \n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "2 & 3 \\\\\n",
    "4 & 7\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "2 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "2 & 3 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "= L \\cdot U\n",
    "$$\n",
    "\n",
    "This decomposition is one of the most important techniques in numerical linear algebra. Its main power lies in efficiently solving linear systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Solving Linear Systems with LU Decomposition\n",
    "\n",
    "The primary motivation for finding the LU decomposition of a matrix $A$ is to solve the system $Ax = b$ more efficiently.\n",
    "\n",
    "The process involves two simple steps:\n",
    "1.  Substitute $A$ with $LU$: The original equation $Ax = b$ becomes $LUx = b$.\n",
    "2.  Introduce an intermediate vector $y$ where $Ux = y$.\n",
    "\n",
    "This breaks the single, difficult problem into two easy-to-solve triangular systems:\n",
    "\n",
    "**Step 1: Solve $Ly = b$ for $y$ using Forward Substitution.**\n",
    "$$ \n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "l_{21} & 1 & 0 \\\\\n",
    "l_{31} & l_{32} & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix} = \n",
    "\\begin{pmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Step 2: Solve $Ux = y$ for $x$ using Back Substitution.**\n",
    "$$ \n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} & u_{13} \\\\\n",
    "0 & u_{22} & u_{23} \\\\\n",
    "0 & 0 & u_{33}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \n",
    "\\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Why is this better?\n",
    "The expensive part of solving a system is the elimination phase (which has a complexity of $O(n^3)$). Finding the LU decomposition is essentially performing this elimination phase on matrix $A$. Once this is done, solving for $x$ using forward and back substitution is very fast ($O(n^2)$).\n",
    "\n",
    "This is incredibly useful when you need to solve the same system $Ax=b$ for **many different vectors $b$**. You perform the expensive decomposition only once, and then rapidly solve for each $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Finding L and U with Gaussian Elimination\n",
    "\n",
    "The LU decomposition is a direct byproduct of the Gaussian Elimination process.\n",
    "\n",
    "- The **U matrix** is simply the **upper triangular matrix** that results from the forward elimination phase.\n",
    "- The **L matrix** is constructed from the **multipliers** used during the elimination. The entry $l_{ij}$ (for $i > j$) is precisely the multiplier used to zero out the element $a_{ij}$.\n",
    "\n",
    "Let's find the LU decomposition for the matrix:\n",
    "$$ A = \n",
    "\\begin{pmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "4 & -6 & 0 \\\\\n",
    "-2 & 7 & 2\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Eliminate the first column\n",
    "The pivot is $a_{11} = 2$.\n",
    "- Multiplier for row 2: $m_{21} = \\frac{4}{2} = 2$. So, $l_{21} = 2$. New row 2 is $L_2 - 2L_1$.\n",
    "- Multiplier for row 3: $m_{31} = \\frac{-2}{2} = -1$. So, $l_{31} = -1$. New row 3 is $L_3 - (-1)L_1 = L_3+L_1$.\n",
    "$$ A^{(1)} = \n",
    "\\begin{pmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "0 & -8 & -2 \\\\\n",
    "0 & 8 & 3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Step 2: Eliminate the second column\n",
    "The pivot is $a_{22} = -8$.\n",
    "- Multiplier for row 3: $m_{32} = \\frac{8}{-8} = -1$. So, $l_{32} = -1$. New row 3 is $L_3 - (-1)L_2 = L_3+L_2$.\n",
    "$$ U = A^{(2)} = \n",
    "\\begin{pmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "0 & -8 & -2 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Resulting Matrices\n",
    "$$ L = \n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "l_{21} & 1 & 0 \\\\\n",
    "l_{31} & l_{32} & 1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "2 & 1 & 0 \\\\\n",
    "-1 & -1 & 1\n",
    "\\end{pmatrix}\n",
    ", \\quad\n",
    "U = \n",
    "\\begin{pmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "0 & -8 & -2 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The Need for Pivoting and the PA=LU Decomposition\n",
    "\n",
    "Just like in standard Gaussian Elimination, the algorithm described above fails if a pivot element is zero. It also suffers from numerical instability if a pivot is very small. Therefore, in any practical implementation, we **must use pivoting**.\n",
    "\n",
    "When we swap rows during elimination, we are effectively reordering the equations of our system. This is equivalent to multiplying our original matrix $A$ by a **Permutation Matrix ($P$)**. A permutation matrix is just an identity matrix with its rows reordered.\n",
    "\n",
    "Therefore, the decomposition of a general square matrix is not $A=LU$, but rather:\n",
    "$$ PA = LU $$\n",
    "\n",
    "Where $P$ is the permutation matrix that records all the row swaps performed during pivoting.\n",
    "\n",
    "#### Solving with $PA=LU$\n",
    "The solving process is slightly modified:\n",
    "1. Start with $Ax = b$.\n",
    "2. Multiply both sides by $P$: $PAx = Pb$. (This applies the row swaps to the vector $b$ as well).\n",
    "3. Substitute $PA$ with $LU$: $LUx = Pb$.\n",
    "4. Let $y = Ux$, which leads to the two familiar triangular solves:\n",
    "   - Solve $Ly = Pb$ for $y$.\n",
    "   - Solve $Ux = y$ for $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Python Implementation\n",
    "\n",
    "Libraries like NumPy and SciPy have highly optimized functions for LU decomposition. `scipy.linalg.lu` is the standard, as it also returns the permutation matrix $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PA=LU Decomposition ---\n",
      "Permutation Matrix (P):\n",
      " [[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "Lower Triangular Matrix (L):\n",
      " [[ 1.   0.   0. ]\n",
      " [ 0.5  1.   0. ]\n",
      " [-0.5  1.   1. ]]\n",
      "\n",
      "Upper Triangular Matrix (U):\n",
      " [[ 4. -6.  0.]\n",
      " [ 0.  4.  1.]\n",
      " [ 0.  0.  1.]]\n",
      "\n",
      "Verification (P @ A):\n",
      " [[ 4. -6.  0.]\n",
      " [ 2.  1.  1.]\n",
      " [-2.  7.  2.]]\n",
      "\n",
      "Verification (L @ U):\n",
      " [[ 4. -6.  0.]\n",
      " [ 2.  1.  1.]\n",
      " [-2.  7.  2.]]\n",
      "\n",
      "--- Solving the System ---\n",
      "Solution x: [1. 1. 2.]\n",
      "NumPy's np.linalg.solve(A, b): [1. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu, solve_triangular\n",
    "\n",
    "# Let's use the example from the manual calculation\n",
    "A = np.array([[2., 1., 1.],\n",
    "              [4., -6., 0.],\n",
    "              [-2., 7., 2.]])\n",
    "\n",
    "b = np.array([5., -2., 9.]) # A consistent b vector for this example\n",
    "\n",
    "# Perform PA = LU decomposition\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print(\"--- PA=LU Decomposition ---\")\n",
    "print(\"Permutation Matrix (P):\\n\", P)\n",
    "print(\"\\nLower Triangular Matrix (L):\\n\", L)\n",
    "print(\"\\nUpper Triangular Matrix (U):\\n\", U)\n",
    "\n",
    "# Verify that P @ A is indeed equal to L @ U\n",
    "print(\"\\nVerification (P @ A):\\n\", P @ A)\n",
    "print(\"\\nVerification (L @ U):\\n\", L @ U)\n",
    "\n",
    "def solve_lu(P, L, U, b):\n",
    "    \"\"\"Solves the system Ax=b using a pre-computed PA=LU decomposition.\"\"\"\n",
    "    # 1. Apply permutations to b -> Pb\n",
    "    Pb = P @ b\n",
    "    \n",
    "    # 2. Solve Ly = Pb for y using forward substitution\n",
    "    # solve_triangular is a highly optimized solver for triangular systems\n",
    "    y = solve_triangular(L, Pb, lower=True)\n",
    "    \n",
    "    # 3. Solve Ux = y for x using back substitution\n",
    "    x = solve_triangular(U, y, lower=False)\n",
    "    \n",
    "    return x\n",
    "\n",
    "print(\"\\n--- Solving the System ---\")\n",
    "solution = solve_lu(P, L, U, b)\n",
    "print(\"Solution x:\", solution)\n",
    "\n",
    "# Verify with numpy's standard solver\n",
    "print(\"NumPy's np.linalg.solve(A, b):\", np.linalg.solve(A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ill-Conditioned Matrices\n",
    "\n",
    "An **ill-conditioned** matrix is one that is very sensitive to small changes in its entries or in the vector $b$. Numerically, this often happens when a matrix is \"close\" to being singular.\n",
    "\n",
    "When solving a system with an ill-conditioned matrix, even with stable methods like LU with pivoting, small floating-point errors can be magnified and lead to large errors in the final solution.\n",
    "\n",
    "A classic example is the Hilbert matrix, where the columns are nearly linearly dependent.\n",
    "\n",
    "The **condition number** of a matrix is a formal measure of this sensitivity. A small condition number (close to 1) means the matrix is well-conditioned. A very large condition number indicates that the matrix is ill-conditioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of our example matrix A: 20.83 (Well-conditioned)\n",
      "\n",
      "Hilbert Matrix of size 5:\n",
      " [[1.         0.5        0.33333333 0.25       0.2       ]\n",
      " [0.5        0.33333333 0.25       0.2        0.16666667]\n",
      " [0.33333333 0.25       0.2        0.16666667 0.14285714]\n",
      " [0.25       0.2        0.16666667 0.14285714 0.125     ]\n",
      " [0.2        0.16666667 0.14285714 0.125      0.11111111]]\n",
      "\n",
      "Condition number of H: 4.77e+05 (Extremely ill-conditioned)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import hilbert\n",
    "\n",
    "# A well-conditioned matrix (our example)\n",
    "cond_A = np.linalg.cond(A)\n",
    "print(f\"Condition number of our example matrix A: {cond_A:.2f} (Well-conditioned)\")\n",
    "\n",
    "# An ill-conditioned matrix (Hilbert matrix)\n",
    "H = hilbert(5)\n",
    "cond_H = np.linalg.cond(H)\n",
    "print(f\"\\nHilbert Matrix of size 5:\\n\", H)\n",
    "print(f\"\\nCondition number of H: {cond_H:.2e} (Extremely ill-conditioned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Key Takeaways: Summary of LU Decomposition\n",
    "\n",
    "Here are the most important points to remember about LU Decomposition:\n",
    "\n",
    "1. **Primary Benefit: Efficiency**\n",
    "\n",
    "   * The main advantage of LU decomposition is its efficiency when solving ( Ax = b ) for **multiple different ( b ) vectors**.\n",
    "   * The expensive part (factorizing ( A ), which is ( O(n^3) )) is done only **once**.\n",
    "   * Each subsequent solution for a new ( b ) is very fast, requiring only one forward and one back substitution (both are ( O(n^2) )).\n",
    "\n",
    "2. **How to Use (with SciPy):**\n",
    "\n",
    "   * Always use a reliable library function like `scipy.linalg.lu`, which performs **pivoting automatically**.\n",
    "   * The function returns three matrices: `P, L, U` such that `P @ A = L @ U`.\n",
    "   * To solve for ( x ), you must apply the permutation matrix to ( b ) first (`Pb = P @ b`) before performing the two triangular solves.\n",
    "\n",
    "3. **Matrix Condition is Crucial**\n",
    "\n",
    "   * LU decomposition with pivoting is a **numerically stable algorithm**, but it cannot fix an inherently problematic matrix.\n",
    "   * If a matrix is **ill-conditioned** (has a very large condition number), it means the problem itself is sensitive to small changes.\n",
    "   * In such cases, even small floating-point errors can be amplified, leading to an inaccurate solution, regardless of the algorithm used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
