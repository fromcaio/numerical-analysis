{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bisection Method\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The **Bisection Method** is one of the simplest and most reliable numerical methods for finding roots. It is a bracketing method, meaning it starts with an interval $[a, b]$ that is known to contain a root and systematically shrinks it.\n",
    "\n",
    "The core idea is straightforward: repeatedly divide the interval in half and select the subinterval where the root must lie, based on the Intermediate Value Theorem. Although it can be slower than other methods, its main advantage is its **guaranteed convergence**—if you start with a valid bracket, it will find a root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stopping Criteria for Iterative Methods\n",
    "\n",
    "Before diving into the algorithm, we must define when to stop. Since numerical methods provide approximations, we need a rule to decide when our answer is \"good enough.\" This rule is called a **stopping criterion**, and it's usually based on a predefined tolerance, $\\epsilon$.\n",
    "\n",
    "Common stopping criteria for a sequence of approximations $x_k$ include:\n",
    "\n",
    "1.  **Interval Width (for bracketing methods)**: The process stops when the length of the interval $[a_k, b_k]$ is smaller than the tolerance.\n",
    "    $$ (b_k - a_k) < \\epsilon $$\n",
    "    *This is the most common criterion for the Bisection Method as it provides a strict upper bound on the absolute error of the root.*\n",
    "\n",
    "2.  **Absolute Error of the Approximation**: Stop when the change between successive approximations is very small.\n",
    "    $$ |x_k - x_{k-1}| < \\epsilon $$\n",
    "\n",
    "3.  **Relative Error of the Approximation**: This is often preferred when the magnitude of the root $x_k$ is very large or very small, as it measures the error relative to the value itself.\n",
    "    $$ \\frac{|x_k - x_{k-1}|}{|x_k|} < \\epsilon, \\quad \\text{for } x_k \\neq 0 $$\n",
    "\n",
    "4.  **Function Value Near Zero**: Stop when the function's value at the approximation is very close to zero.\n",
    "    $$ |f(x_k)| < \\epsilon $$\n",
    "    *This can be misleading if the function is very flat near the root (a small $|f(x_k)|$ doesn't guarantee $x_k$ is close to the true root).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Bisection Method Algorithm\n",
    "\n",
    "#### Preconditions:\n",
    "1.  A function $f(x)$ that is **continuous** on an interval $[a, b]$.\n",
    "2.  The function values at the endpoints have **opposite signs**, i.e., $f(a) \\cdot f(b) < 0$. (This brackets the root).\n",
    "\n",
    "#### Algorithm Steps:\n",
    "1.  **Initialization**: Choose an initial interval $[a, b]$ and a tolerance $\\epsilon > 0$.\n",
    "2.  **Iteration**: Repeat the following steps until the stopping criterion is met:\n",
    "\n",
    "    a. Calculate the midpoint of the interval: $x_m = \\frac{a + b}{2}$.\n",
    "\n",
    "    b. Evaluate the function at the midpoint, $f(x_m)$.\n",
    "\n",
    "    c. **Update the interval**:<br>\n",
    "        If $f(a) \\times f(x_m) < 0$, the root is in the left half. Set the new interval to $[a, x_m]$ (i.e., set $b = x_m$).<br>\n",
    "        If $f(b) \\cdot f(x_m) < 0$, the root is in the right half. Set the new interval to $[x_m, b]$ (i.e., set $a = x_m$).<br>\n",
    "        If $f(x_m) = 0$, the exact root has been found, and the algorithm can stop.<br>\n",
    "\n",
    "3.  **Termination**: Once the stopping criterion (e.g., $b - a < \\epsilon$) is satisfied, the best approximation for the root is the midpoint of the final interval, $\\frac{a+b}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Example: $f(x) = x^3 - 9x + 3$\n",
    "\n",
    "Let's find the root in the interval $I = [0, 1]$ with a tolerance of $\\epsilon = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def f(x):\n",
    "    return x**3 - 9*x + 3\n",
    "\n",
    "a, b = 0.0, 1.0\n",
    "tol = 0.1\n",
    "k = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "# Check initial condition\n",
    "if f(a) * f(b) >= 0:\n",
    "    print(\"Bisection method fails. f(a) and f(b) must have opposite signs.\")\n",
    "else:\n",
    "    while (b - a) >= tol:\n",
    "        k += 1\n",
    "        xm = (a + b) / 2\n",
    "        fxm = f(xm)\n",
    "        \n",
    "        results.append([k, a, b, xm, f(a), f(b), fxm, b-a])\n",
    "        \n",
    "        if f(a) * fxm < 0:\n",
    "            b = xm\n",
    "        elif f(b) * fxm < 0:\n",
    "            a = xm\n",
    "        else: # f(xm) is exactly 0\n",
    "            break\n",
    "            \n",
    "    # Final approximation\n",
    "    root_approx = (a + b) / 2\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=['k', 'a', 'b', 'xm', 'f(a)', 'f(b)', 'f(xm)', 'b-a'])\n",
    "    df.set_index('k', inplace=True)\n",
    "    print(\"--- Bisection Method Iterations ---\")\n",
    "    display(df)\n",
    "    print(f\"\\nRoot approximation after {k} iterations: {root_approx:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bisection_method(func, a, b, tol=1e-6, max_iter=100):\n",
    "    \"\"\"\n",
    "    Finds a root of a function using the bisection method.\n",
    "    \n",
    "    Args:\n",
    "        func: The function for which to find a root.\n",
    "        a, b: The endpoints of the interval [a, b].\n",
    "        tol: The desired tolerance (stopping criterion for interval width).\n",
    "        max_iter: The maximum number of iterations to perform.\n",
    "        \n",
    "    Returns:\n",
    "        The approximate root, or None if the method fails.\n",
    "    \"\"\"\n",
    "    # Check if a root is guaranteed to be in the interval\n",
    "    if func(a) * func(b) >= 0:\n",
    "        print(\"Bisection method fails: f(a) and f(b) must have opposite signs.\")\n",
    "        return None\n",
    "    \n",
    "    iterations = 0\n",
    "    while (b - a) / 2.0 > tol and iterations < max_iter:\n",
    "        midpoint = (a + b) / 2.0\n",
    "        \n",
    "        if func(midpoint) == 0:\n",
    "            return midpoint # Exact root found\n",
    "        elif func(a) * func(midpoint) < 0:\n",
    "            b = midpoint\n",
    "        else:\n",
    "            a = midpoint\n",
    "            \n",
    "        iterations += 1\n",
    "        \n",
    "    return (a + b) / 2.0\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Define the function f(x) = sqrt(x) - 5e^(-x)\n",
    "def f2(x):\n",
    "    return np.sqrt(x) - 5 * np.exp(-x)\n",
    "\n",
    "# Define the interval and tolerance\n",
    "interval_a = 1.0\n",
    "interval_b = 2.0\n",
    "tolerance = 1e-5\n",
    "\n",
    "# Find the root\n",
    "root = bisection_method(f2, interval_a, interval_b, tol=tolerance)\n",
    "\n",
    "if root is not None:\n",
    "    print(f\"The approximate root is: {root:.6f}\")\n",
    "    print(f\"The value of f(root) is: {f2(root):.6e}\")\n",
    "\n",
    "    # --- Visualization ---\n",
    "    x_vals = np.linspace(0, 3, 400)\n",
    "    y_vals = f2(x_vals)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x_vals, y_vals, label='$f(x) = \\sqrt{x} - 5e^{-x}$')\n",
    "    plt.axhline(0, color='black', lw=0.5)\n",
    "    plt.scatter(root, f2(root), color='red', zorder=5, label=f'Found Root ≈ {root:.4f}')\n",
    "    plt.title('Bisection Method Root Finding')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estimating the Number of Iterations\n",
    "\n",
    "A unique advantage of the Bisection Method is that we can predict the exact number of iterations, $k$, required to achieve a certain tolerance, $\\epsilon$.\n",
    "\n",
    "Let the initial interval be $[a_0, b_0]$. After one iteration, the interval width is $\\frac{b_0 - a_0}{2}$. After $k$ iterations, the width will be:\n",
    "$$ b_k - a_k = \\frac{b_0 - a_0}{2^k} $$\n",
    "\n",
    "We want to find the smallest $k$ that satisfies our stopping criterion, $b_k - a_k < \\epsilon$. Therefore:\n",
    "$$ \\frac{b_0 - a_0}{2^k} < \\epsilon $$\n",
    "\n",
    "Solving for $k$:\n",
    "$$ 2^k > \\frac{b_0 - a_0}{\\epsilon} $$\n",
    "$$ k \\cdot \\log(2) > \\log(b_0 - a_0) - \\log(\\epsilon) $$\n",
    "$$ k > \\frac{\\log(b_0 - a_0) - \\log(\\epsilon)}{\\log(2)} $$\n",
    "\n",
    "Since $k$ must be an integer, we take the ceiling of this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bisection_iterations(a, b, tol):\n",
    "    \"\"\"Estimates the number of iterations required for the bisection method.\"\"\"\n",
    "    if tol <= 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    k = (np.log(b - a) - np.log(tol)) / np.log(2)\n",
    "    return np.ceil(k)\n",
    "\n",
    "# Estimate for the previous example\n",
    "a, b = 1.0, 2.0\n",
    "tolerance = 1e-5\n",
    "\n",
    "required_iterations = estimate_bisection_iterations(a, b, tolerance)\n",
    "print(f\"For interval [{a}, {b}] and tolerance {tolerance}:\")\n",
    "print(f\"Predicted number of iterations: {int(required_iterations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advantages and Disadvantages\n",
    "\n",
    "#### Advantages:\n",
    "1.  **Guaranteed Convergence**: If the initial interval brackets a root, the method is guaranteed to converge to that root.\n",
    "2.  **Simplicity**: The algorithm is easy to understand and implement.\n",
    "3.  **Error Bound**: The absolute error is always less than half the length of the current interval, providing a predictable and strict error bound.\n",
    "\n",
    "#### Disadvantages:\n",
    "1.  **Slow Convergence**: The method converges linearly, which is much slower than other methods like Newton's. The interval width is only halved at each step, regardless of the function's shape.\n",
    "2.  **Ignores Function Information**: It only uses the *sign* of $f(x)$ at the endpoints and midpoint, ignoring the magnitude. A point where $f(x)$ is very close to zero is treated the same as one where it's far away."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
